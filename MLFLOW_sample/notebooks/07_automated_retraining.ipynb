{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a86ba8e2-d471-4562-9e91-1dd943a85364",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MAGIC %md\n",
    "# MAGIC # 06 - Automated Model Retraining Pipeline\n",
    "# MAGIC \n",
    "# MAGIC **End-to-end automated pipeline for model retraining and deployment**\n",
    "# MAGIC \n",
    "# MAGIC ## Objectives:\n",
    "# MAGIC - Check if retraining is needed based on monitoring metrics\n",
    "# MAGIC - Retrain model with latest data\n",
    "# MAGIC - Compare new model with production model\n",
    "# MAGIC - Auto-promote if performance improves\n",
    "# MAGIC - Send notifications and reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "098dcb6c-597b-452d-9e61-01a030e10e5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 1. Setup & Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "610c52c5-7b73-4f7f-af7a-fbd85a569543",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Restart Python to ensure clean imports\n",
    "%restart_python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d9d0afa-4108-42a8-a48e-b0c0bfee608b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Standard imports\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Imports complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfdadaea-c023-4b3f-8fb8-d4b5e8655ccc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 2. Project Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f669cda1-9b07-4a11-ae68-7ad5bc7ea383",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AUTOMATED RETRAINING PIPELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define project root\n",
    "project_root = \"/Workspace/COMM - Commercial Analytics (CMAN)/MMM Quattro 2025/Satish/MLFLOW_sample\"\n",
    "\n",
    "# Add to path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"\\nüìÇ Project root: {project_root}\")\n",
    "print(f\"‚úÖ Added to sys.path\")\n",
    "\n",
    "# Import custom modules\n",
    "from src.utils import ConfigLoader, DataLoader, MLflowLogger, safe_display\n",
    "from src.data_processing import DataProcessor\n",
    "from src.feature_engineering import FeatureEngineer\n",
    "from src.model import ModelTrainer\n",
    "\n",
    "print(f\"‚úÖ Custom modules imported\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de841da3-f648-457b-bda6-8e744c785582",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 3. Load Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07e58511-8b1f-4b5b-ae8a-625709957035",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LOADING CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config_path = f'{project_root}/config/config.yaml'\n",
    "config = ConfigLoader.load_config(config_path)\n",
    "\n",
    "print(f\"\\n‚úÖ Configuration loaded\")\n",
    "print(f\"  ‚Ä¢ Project: {config['project']['name']}\")\n",
    "print(f\"  ‚Ä¢ Model Registry: {config['mlflow']['model_registry_name']}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12c5120d-0f1a-4b0d-9f70-c8b89c40c52f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 4. Setup MLflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1163e4ca-48fe-464c-8c9d-630ae84eda20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SETTING UP MLFLOW\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "experiment_name = config['mlflow']['experiment_name']\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Initialize MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "print(f\"\\n‚úÖ MLflow experiment set: {experiment_name}\")\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "print(f\"  ‚Ä¢ Experiment ID: {experiment.experiment_id}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fae1b76-4763-4415-b487-45269eab5fae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 5. Check Retraining Criteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "327bfc8e-e787-470f-8d60-1ee006ce0b80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CHECKING RETRAINING CRITERIA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define retraining thresholds\n",
    "RETRAINING_THRESHOLDS = {\n",
    "    'max_rmse_increase': 10,      # Retrain if RMSE increases by >10%\n",
    "    'max_mae_increase': 10,       # Retrain if MAE increases by >10%\n",
    "    'min_r2_decrease': 5,         # Retrain if R¬≤ decreases by >5%\n",
    "    'max_drift_features': 2,      # Retrain if >2 features show drift\n",
    "    'max_days_since_training': 30 # Retrain if model is >30 days old\n",
    "}\n",
    "\n",
    "print(f\"\\nüìã Retraining Thresholds:\")\n",
    "for key, value in RETRAINING_THRESHOLDS.items():\n",
    "    print(f\"  ‚Ä¢ {key}: {value}\")\n",
    "\n",
    "# Load latest monitoring report\n",
    "processed_path = config['data']['processed_path']\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Find latest monitoring report\n",
    "monitoring_files = glob.glob(f\"{processed_path}monitoring_report_*.json\")\n",
    "\n",
    "retraining_needed = False\n",
    "retraining_reasons = []\n",
    "\n",
    "if monitoring_files:\n",
    "    latest_report = max(monitoring_files, key=os.path.getctime)\n",
    "    \n",
    "    with open(latest_report, 'r') as f:\n",
    "        monitoring_data = json.load(f)\n",
    "    \n",
    "    print(f\"\\nüìä Latest Monitoring Report: {os.path.basename(latest_report)}\")\n",
    "    \n",
    "    # Check performance drift\n",
    "    drift_metrics = monitoring_data.get('drift_metrics', {})\n",
    "    \n",
    "    if drift_metrics.get('rmse_change_pct', 0) > RETRAINING_THRESHOLDS['max_rmse_increase']:\n",
    "        retraining_needed = True\n",
    "        retraining_reasons.append(f\"RMSE increased by {drift_metrics['rmse_change_pct']:.2f}%\")\n",
    "    \n",
    "    if drift_metrics.get('mae_change_pct', 0) > RETRAINING_THRESHOLDS['max_mae_increase']:\n",
    "        retraining_needed = True\n",
    "        retraining_reasons.append(f\"MAE increased by {drift_metrics['mae_change_pct']:.2f}%\")\n",
    "    \n",
    "    if drift_metrics.get('r2_change_pct', 0) < -RETRAINING_THRESHOLDS['min_r2_decrease']:\n",
    "        retraining_needed = True\n",
    "        retraining_reasons.append(f\"R¬≤ decreased by {abs(drift_metrics['r2_change_pct']):.2f}%\")\n",
    "    \n",
    "    # Check feature drift\n",
    "    feature_drift_summary = monitoring_data.get('feature_drift_summary', {})\n",
    "    drifted_features = feature_drift_summary.get('drifted_features', 0)\n",
    "    \n",
    "    if drifted_features > RETRAINING_THRESHOLDS['max_drift_features']:\n",
    "        retraining_needed = True\n",
    "        retraining_reasons.append(f\"{drifted_features} features showing drift\")\n",
    "    \n",
    "    # Check alerts\n",
    "    alert_count = monitoring_data.get('alert_count', 0)\n",
    "    if alert_count > 0:\n",
    "        retraining_needed = True\n",
    "        retraining_reasons.append(f\"{alert_count} monitoring alerts triggered\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è No monitoring report found\")\n",
    "    retraining_needed = True\n",
    "    retraining_reasons.append(\"No monitoring data available\")\n",
    "\n",
    "# Check model age\n",
    "model_name = config['mlflow']['model_registry_name']\n",
    "try:\n",
    "    model_versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "    if model_versions:\n",
    "        latest_version = model_versions[0]\n",
    "        run = client.get_run(latest_version.run_id)\n",
    "        \n",
    "        # Get run timestamp\n",
    "        run_timestamp = datetime.fromtimestamp(run.info.start_time / 1000)\n",
    "        days_since_training = (datetime.now() - run_timestamp).days\n",
    "        \n",
    "        print(f\"\\nüìÖ Model Age: {days_since_training} days\")\n",
    "        \n",
    "        if days_since_training > RETRAINING_THRESHOLDS['max_days_since_training']:\n",
    "            retraining_needed = True\n",
    "            retraining_reasons.append(f\"Model is {days_since_training} days old\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Decision\n",
    "print(f\"\\n{'='*60}\")\n",
    "if retraining_needed:\n",
    "    print(f\"üîÑ RETRAINING NEEDED\")\n",
    "    print(f\"\\nüìã Reasons:\")\n",
    "    for reason in retraining_reasons:\n",
    "        print(f\"  ‚Ä¢ {reason}\")\n",
    "else:\n",
    "    print(f\"‚úÖ RETRAINING NOT NEEDED - Model performance is stable\")\n",
    "\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32dac898-6ff2-4730-8b1c-34a47c13558b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 6. Load and Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5472cc64-6285-4c11-95ce-57fea0961f67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Only proceed if retraining is needed\n",
    "if retraining_needed:\n",
    "    print(\"=\"*60)\n",
    "    print(\"LOADING AND PREPARING DATA\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load raw data\n",
    "    raw_data_path = config['data']['raw_path']\n",
    "    df = pd.read_csv(raw_data_path)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Data loaded: {df.shape}\")\n",
    "    \n",
    "    # Initialize processors\n",
    "    data_processor = DataProcessor(config)\n",
    "    feature_engineer = FeatureEngineer(config)\n",
    "    \n",
    "    # Validate data\n",
    "    is_valid, validation_report = data_processor.validate_data(df)\n",
    "    \n",
    "    if not is_valid:\n",
    "        print(f\"\\n‚ö†Ô∏è Data validation issues found:\")\n",
    "        print(validation_report)\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ Data validation passed\")\n",
    "    \n",
    "    # Create features\n",
    "    print(f\"\\nüîß Creating features...\")\n",
    "    df_featured = feature_engineer.create_features(df)\n",
    "    \n",
    "    # Encode categorical features\n",
    "    print(f\"üîß Encoding categorical features...\")\n",
    "    df_encoded = data_processor.encode_categorical(df_featured)\n",
    "    \n",
    "    # Split features and target\n",
    "    target_col = config['preprocessing']['target']\n",
    "    X = df_encoded.drop(columns=[target_col])\n",
    "    y = df_encoded[target_col]\n",
    "    \n",
    "    # Train-test split\n",
    "    test_size = config['preprocessing']['test_size']\n",
    "    random_state = config['preprocessing']['random_state']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    print(f\"üîß Scaling features...\")\n",
    "    X_train_scaled, X_test_scaled = data_processor.scale_features(X_train, X_test)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Data preparation complete\")\n",
    "    print(f\"  ‚Ä¢ Training set: {X_train_scaled.shape}\")\n",
    "    print(f\"  ‚Ä¢ Test set: {X_test_scaled.shape}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"\\n‚è≠Ô∏è Skipping data preparation - retraining not needed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d05603c-b92d-4a90-b8d9-3d2c0e072585",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 7. Train New Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "726b1a61-ce85-408c-89ff-0f6d05f305a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if retraining_needed:\n",
    "    print(\"=\"*60)\n",
    "    print(\"TRAINING NEW MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Initialize model trainer\n",
    "    model_trainer = ModelTrainer(config)\n",
    "    \n",
    "    # Get enabled models\n",
    "    enabled_models = {\n",
    "        name: params \n",
    "        for name, params in config['models'].items() \n",
    "        if params.get('enabled', False)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nü§ñ Training {len(enabled_models)} models...\")\n",
    "    \n",
    "    # Train all models\n",
    "    results = {}\n",
    "    \n",
    "    for model_name in enabled_models.keys():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training: {model_name.replace('_', ' ').title()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        result = model_trainer.train_model(\n",
    "            model_name=model_name,\n",
    "            X_train=X_train_scaled,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test_scaled,\n",
    "            y_test=y_test\n",
    "        )\n",
    "        \n",
    "        results[model_name] = result\n",
    "        \n",
    "        print(f\"\\n‚úÖ {model_name} complete\")\n",
    "        print(f\"  ‚Ä¢ Test RMSE: ${result['test_metrics']['rmse']:,.2f}\")\n",
    "        print(f\"  ‚Ä¢ Test R¬≤: {result['test_metrics']['r2']:.4f}\")\n",
    "    \n",
    "    # Find best model\n",
    "    best_model_name = min(results.keys(), key=lambda k: results[k]['test_metrics']['rmse'])\n",
    "    best_result = results[best_model_name]\n",
    "    new_model = best_result['model']\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üèÜ BEST NEW MODEL: {best_model_name.replace('_', ' ').title()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  ‚Ä¢ Test RMSE: ${best_result['test_metrics']['rmse']:,.2f}\")\n",
    "    print(f\"  ‚Ä¢ Test MAE:  ${best_result['test_metrics']['mae']:,.2f}\")\n",
    "    print(f\"  ‚Ä¢ Test R¬≤:   {best_result['test_metrics']['r2']:.4f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚è≠Ô∏è Skipping model training - retraining not needed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c22c4fc-81cc-4f06-abc6-9dac6e5b7058",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 8. Compare with Production Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4a427ff-f78f-447d-be0f-f80882bcfb2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if retraining_needed:\n",
    "    print(\"=\"*60)\n",
    "    print(\"COMPARING WITH PRODUCTION MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load production model\n",
    "    model_registry_name = config['mlflow']['model_registry_name']\n",
    "    \n",
    "    try:\n",
    "        production_model_uri = f\"models:/{model_registry_name}/Production\"\n",
    "        production_model = mlflow.sklearn.load_model(production_model_uri)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Production model loaded\")\n",
    "        \n",
    "        # Get production model predictions\n",
    "        y_pred_production = production_model.predict(X_test_scaled)\n",
    "        \n",
    "        # Calculate production model metrics\n",
    "        production_metrics = {\n",
    "            'rmse': np.sqrt(mean_squared_error(y_test, y_pred_production)),\n",
    "            'mae': mean_absolute_error(y_test, y_pred_production),\n",
    "            'r2': r2_score(y_test, y_pred_production)\n",
    "        }\n",
    "        \n",
    "        # Get new model predictions\n",
    "        y_pred_new = new_model.predict(X_test_scaled)\n",
    "        \n",
    "        # Calculate new model metrics\n",
    "        new_metrics = {\n",
    "            'rmse': np.sqrt(mean_squared_error(y_test, y_pred_new)),\n",
    "            'mae': mean_absolute_error(y_test, y_pred_new),\n",
    "            'r2': r2_score(y_test, y_pred_new)\n",
    "        }\n",
    "        \n",
    "        # Calculate improvements\n",
    "        improvements = {\n",
    "            'rmse_improvement': ((production_metrics['rmse'] - new_metrics['rmse']) / production_metrics['rmse']) * 100,\n",
    "            'mae_improvement': ((production_metrics['mae'] - new_metrics['mae']) / production_metrics['mae']) * 100,\n",
    "            'r2_improvement': ((new_metrics['r2'] - production_metrics['r2']) / production_metrics['r2']) * 100\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nüìä Model Comparison:\")\n",
    "        print(f\"\\n  Production Model:\")\n",
    "        print(f\"    ‚Ä¢ RMSE: ${production_metrics['rmse']:,.2f}\")\n",
    "        print(f\"    ‚Ä¢ MAE:  ${production_metrics['mae']:,.2f}\")\n",
    "        print(f\"    ‚Ä¢ R¬≤:   {production_metrics['r2']:.4f}\")\n",
    "        \n",
    "        print(f\"\\n  New Model:\")\n",
    "        print(f\"    ‚Ä¢ RMSE: ${new_metrics['rmse']:,.2f}\")\n",
    "        print(f\"    ‚Ä¢ MAE:  ${new_metrics['mae']:,.2f}\")\n",
    "        print(f\"    ‚Ä¢ R¬≤:   {new_metrics['r2']:.4f}\")\n",
    "        \n",
    "        print(f\"\\n  Improvements:\")\n",
    "        print(f\"    ‚Ä¢ RMSE: {improvements['rmse_improvement']:+.2f}%\")\n",
    "        print(f\"    ‚Ä¢ MAE:  {improvements['mae_improvement']:+.2f}%\")\n",
    "        print(f\"    ‚Ä¢ R¬≤:   {improvements['r2_improvement']:+.2f}%\")\n",
    "        \n",
    "        # Decide if new model is better\n",
    "        PROMOTION_THRESHOLD = 2  # New model must be at least 2% better\n",
    "        \n",
    "        should_promote = (\n",
    "            improvements['rmse_improvement'] > PROMOTION_THRESHOLD or\n",
    "            improvements['r2_improvement'] > PROMOTION_THRESHOLD\n",
    "        )\n",
    "        \n",
    "        if should_promote:\n",
    "            print(f\"\\n‚úÖ New model shows significant improvement - will be promoted\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è New model does not show significant improvement - will not be promoted\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è Could not load production model: {e}\")\n",
    "        print(f\"  ‚Ä¢ Assuming this is the first model - will promote\")\n",
    "        should_promote = True\n",
    "        production_metrics = None\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚è≠Ô∏è Skipping model comparison - retraining not needed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1b5b01e-439e-4c3d-aff4-44d2afdfabfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 9. Register and Promote New Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbce8302-9426-41c3-a33d-1a896d10e31b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if retraining_needed and should_promote:\n",
    "    print(\"=\"*60)\n",
    "    print(\"REGISTERING AND PROMOTING NEW MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Register new model\n",
    "        with mlflow.start_run(run_name=f\"retrained_{best_model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
    "            \n",
    "            # Log metadata\n",
    "            mlflow.log_param(\"model_type\", best_model_name)\n",
    "            mlflow.log_param(\"retraining_trigger\", \", \".join(retraining_reasons))\n",
    "            mlflow.log_param(\"auto_retrained\", True)\n",
    "            \n",
    "            # Log parameters\n",
    "            if best_result['params']:\n",
    "                MLflowLogger.log_params_from_dict(best_result['params'])\n",
    "            \n",
    "            # Log metrics\n",
    "            MLflowLogger.log_metrics_from_dict({\n",
    "                f\"train_{k}\": v for k, v in best_result['train_metrics'].items()\n",
    "            })\n",
    "            MLflowLogger.log_metrics_from_dict({\n",
    "                f\"test_{k}\": v for k, v in best_result['test_metrics'].items()\n",
    "            })\n",
    "            \n",
    "            # Log improvements if production model exists\n",
    "            if production_metrics:\n",
    "                MLflowLogger.log_metrics_from_dict({\n",
    "                    f\"improvement_{k}\": v for k, v in improvements.items()\n",
    "                })\n",
    "            \n",
    "            # Register model\n",
    "            mlflow.sklearn.log_model(\n",
    "                sk_model=new_model,\n",
    "                artifact_path=\"model\",\n",
    "                registered_model_name=model_registry_name\n",
    "            )\n",
    "            \n",
    "            run_id = mlflow.active_run().info.run_id\n",
    "        \n",
    "        print(f\"\\n‚úÖ New model registered\")\n",
    "        print(f\"  ‚Ä¢ Run ID: {run_id}\")\n",
    "        \n",
    "        # Get the new model version\n",
    "        import time\n",
    "        time.sleep(2)  # Wait for registration to complete\n",
    "        \n",
    "        model_versions = client.search_model_versions(f\"name='{model_registry_name}'\")\n",
    "        new_version = model_versions[0]\n",
    "        \n",
    "        print(f\"  ‚Ä¢ Version: {new_version.version}\")\n",
    "        \n",
    "        # Transition to Production\n",
    "        client.transition_model_version_stage(\n",
    "            name=model_registry_name,\n",
    "            version=new_version.version,\n",
    "            stage=\"Production\",\n",
    "            archive_existing_versions=True\n",
    "        )\n",
    "        \n",
    "        # Update description\n",
    "        client.update_model_version(\n",
    "            name=model_registry_name,\n",
    "            version=new_version.version,\n",
    "            description=f\"Auto-retrained model. Reasons: {', '.join(retraining_reasons)}. Deployed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n‚úÖ Model promoted to Production\")\n",
    "        print(f\"  ‚Ä¢ Previous versions archived\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during registration/promotion: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "elif retraining_needed and not should_promote:\n",
    "    print(\"\\n‚è≠Ô∏è Skipping promotion - new model not significantly better\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚è≠Ô∏è Skipping registration - retraining not needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd52525a-2681-4504-be58-b13bd0f9bf68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 10. Generate Retraining Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4a3c0a6-437c-492a-8862-c4877b957a8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if retraining_needed:\n",
    "    print(\"=\"*60)\n",
    "    print(\"GENERATING RETRAINING REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create retraining report\n",
    "    retraining_report = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'retraining_needed': retraining_needed,\n",
    "        'retraining_reasons': retraining_reasons,\n",
    "        'model_promoted': should_promote if 'should_promote' in locals() else False,\n",
    "        \n",
    "        'new_model': {\n",
    "            'name': best_model_name,\n",
    "            'type': type(new_model).__name__,\n",
    "            'metrics': {\n",
    "                'rmse': float(new_metrics['rmse']),\n",
    "                'mae': float(new_metrics['mae']),\n",
    "                'r2': float(new_metrics['r2'])\n",
    "            }\n",
    "        } if 'new_model' in locals() else None,\n",
    "        \n",
    "        'production_model': {\n",
    "            'metrics': {\n",
    "                'rmse': float(production_metrics['rmse']),\n",
    "                'mae': float(production_metrics['mae']),\n",
    "                'r2': float(production_metrics['r2'])\n",
    "            }\n",
    "        } if production_metrics else None,\n",
    "        \n",
    "        'improvements': {\n",
    "            k: float(v) for k, v in improvements.items()\n",
    "        } if 'improvements' in locals() else None,\n",
    "        \n",
    "        'training_data': {\n",
    "            'train_size': len(X_train_scaled) if 'X_train_scaled' in locals() else 0,\n",
    "            'test_size': len(X_test_scaled) if 'X_test_scaled' in locals() else 0,\n",
    "            'features': list(X_train_scaled.columns) if 'X_train_scaled' in locals() else []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save report\n",
    "    report_path = f\"{processed_path}retraining_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    with open(report_path, 'w') as f:\n",
    "        json.dump(retraining_report, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Retraining report saved: {report_path}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚è≠Ô∏è Skipping report generation - retraining not needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4660ff57-6a0f-403b-990d-740ea38ebb7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MAGIC %md\n",
    "# MAGIC ## 11. Pipeline Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1282588c-1499-4e23-857b-fd680e21bbc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AUTOMATED RETRAINING PIPELINE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìÖ Execution Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(f\"\\nüîç Retraining Decision:\")\n",
    "print(f\"  ‚Ä¢ Needed: {'Yes' if retraining_needed else 'No'}\")\n",
    "\n",
    "if retraining_needed:\n",
    "    print(f\"\\nüìã Reasons:\")\n",
    "    for reason in retraining_reasons:\n",
    "        print(f\"  ‚Ä¢ {reason}\")\n",
    "    \n",
    "    if 'new_model' in locals():\n",
    "        print(f\"\\nü§ñ New Model:\")\n",
    "        print(f\"  ‚Ä¢ Type: {best_model_name.replace('_', ' ').title()}\")\n",
    "        print(f\"  ‚Ä¢ RMSE: ${new_metrics['rmse']:,.2f}\")\n",
    "        print(f\"  ‚Ä¢ MAE:  ${new_metrics['mae']:,.2f}\")\n",
    "        print(f\"  ‚Ä¢ R¬≤:   {new_metrics['r2']:.4f}\")\n",
    "    \n",
    "    if 'improvements' in locals():\n",
    "        print(f\"\\nüìà Improvements:\")\n",
    "        print(f\"  ‚Ä¢ RMSE: {improvements['rmse_improvement']:+.2f}%\")\n",
    "        print(f\"  ‚Ä¢ MAE:  {improvements['mae_improvement']:+.2f}%\")\n",
    "        print(f\"  ‚Ä¢ R¬≤:   {improvements['r2_improvement']:+.2f}%\")\n",
    "    \n",
    "    if 'should_promote' in locals():\n",
    "        print(f\"\\nüöÄ Promotion:\")\n",
    "        print(f\"  ‚Ä¢ Promoted: {'Yes' if should_promote else 'No'}\")\n",
    "        if should_promote:\n",
    "            print(f\"  ‚Ä¢ Status: New model is now in Production\")\n",
    "        else:\n",
    "            print(f\"  ‚Ä¢ Reason: Improvement below threshold\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Current model performance is stable\")\n",
    "    print(f\"  ‚Ä¢ No action taken\")\n",
    "\n",
    "print(f\"\\nüìÅ Generated Files:\")\n",
    "if retraining_needed:\n",
    "    print(f\"  ‚Ä¢ retraining_report_*.json\")\n",
    "else:\n",
    "    print(f\"  ‚Ä¢ None\")\n",
    "\n",
    "print(f\"\\nüí° Next Steps:\")\n",
    "if retraining_needed and should_promote:\n",
    "    print(f\"  ‚Ä¢ Monitor new production model\")\n",
    "    print(f\"  ‚Ä¢ Update documentation\")\n",
    "    print(f\"  ‚Ä¢ Notify stakeholders\")\n",
    "elif retraining_needed and not should_promote:\n",
    "    print(f\"  ‚Ä¢ Investigate why new model didn't improve\")\n",
    "    print(f\"  ‚Ä¢ Consider different algorithms or features\")\n",
    "    print(f\"  ‚Ä¢ Review data quality\")\n",
    "else:\n",
    "    print(f\"  ‚Ä¢ Continue monitoring\")\n",
    "    print(f\"  ‚Ä¢ Schedule next check\")\n",
    "\n",
    "print(f\"\\n‚úÖ Pipeline execution complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ca7be38-883b-42fc-afde-22c73247ad0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "07_automated_retraining",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
